#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
"""

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π
import os
import torch
import pickle
from models import BearingClassifier
from dataset import load_and_preprocess_data, prepare_data_loaders
from training import train_model, evaluate_model
from prediction import predict_test_bearing
from visualization import visualize_results
from utils import set_seeds, print_summary, print_model_summary
import torch.nn as nn

def save_model_and_preprocessors(model, scaler, pca, input_size, model_dir="saved_models"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤"""
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    os.makedirs(model_dir, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model_path = os.path.join(model_dir, "bearing_classifier.pth")
    torch.save({
        'model_state_dict': model.state_dict(),
        'input_size': input_size,
        'model_architecture': model.__class__.__name__
    }, model_path)
    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler
    scaler_path = os.path.join(model_dir, "scaler.pkl")
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)
    print(f"Scaler —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {scaler_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ PCA
    pca_path = os.path.join(model_dir, "pca.pkl")
    with open(pca_path, 'wb') as f:
        pickle.dump(pca, f)
    print(f"PCA —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {pca_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
    metadata = {
        'input_size': input_size,
        'model_architecture': 'BearingClassifier',
        'description': '–ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞'
    }
    metadata_path = os.path.join(model_dir, "model_metadata.pkl")
    with open(metadata_path, 'wb') as f:
        pickle.dump(metadata, f)
    print(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {metadata_path}")

def create_model_visualization(model, input_size, save_dir="visualizations"):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    try:
        from visualtorch import graph
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        os.makedirs(save_dir, exist_ok=True)
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ CPU –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        model_cpu = model.cpu()
        model_cpu.eval()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        input_shape = (1, input_size)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        image = graph.graph_view(
            model=model_cpu,
            input_shape=input_shape,
            to_file=os.path.join(save_dir, "trained_model_architecture.png"),
            show_neurons=True,
            layer_spacing=300,
            node_size=60,
            background_fill='white',
            connector_fill='red',
            connector_width=2
        )
        
        print(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {os.path.join(save_dir, 'trained_model_architecture.png')}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        print(f"üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size}")
        print(f"   ‚Ä¢ –§–æ—Ä–º–∞—Ç: {image.format}")
        print(f"   ‚Ä¢ –†–µ–∂–∏–º: {image.mode}")
        
        # –ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–µ–≤
        layer_count = 0
        for name, module in model_cpu.named_modules():
            if isinstance(module, (nn.Linear, nn.ReLU, nn.BatchNorm1d, nn.Dropout, nn.Sigmoid)):
                layer_count += 1
        
        print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤: {layer_count}")
            
    except ImportError:
        print("‚ö†Ô∏è  visualtorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install visualtorch")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=== –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ===\n")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    set_seeds()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X, y = load_and_preprocess_data()
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    train_loader, test_loader, scaler, pca = prepare_data_loaders(X, y)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    input_size = train_loader.dataset.features.shape[1]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ PCA
    model = BearingClassifier(input_size)
    print(f"\n–°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å —Å {input_size} –≤—Ö–æ–¥–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model, train_losses, test_losses, test_accuracies = train_model(
        model, train_loader, test_loader
    )
    
    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    accuracy, predictions, labels = evaluate_model(model, test_loader, scaler)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–¥—à–∏–ø–Ω–∏–∫–∞
    mean_pred, state, state_value = predict_test_bearing(model, scaler, pca)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
    visualize_results(train_losses, test_losses, test_accuracies, predictions, labels)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏...")
    create_model_visualization(model, input_size)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
    print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    save_model_and_preprocessors(model, scaler, pca, input_size)
    
    # –í—ã–≤–æ–¥ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ —Å–∞–º–∞—Ä–∏ –ø–æ –º–æ–¥–µ–ª–∏
    print_model_summary(model, input_size, train_losses, test_losses, test_accuracies,
                       accuracy, predictions, labels, mean_pred, state, state_value)
    
    # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ
    print_summary(accuracy, state, state_value, mean_pred)

if __name__ == "__main__":
    main()
